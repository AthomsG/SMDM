d2_3 <- d1_3 - sigma*sqrt(Time-t)
price_put3 <- pnorm(-d2_3)*K3*exp(-r*(Time-t))-pnorm(-d1_3)*S0
#part a
#delta of portfolio
delta1 <- -pnorm(-d1_1)
delta2 <- -pnorm(-d1_2)
delta3 <- -pnorm(-d1_3)
delta_portfolio <- -delta1 + 2* delta2 - delta3
#gamma of portfolio
gamma1 <- dnorm(d1_1)/(S0 * sigma * sqrt(T-t))
gamma2 <- dnorm(d1_3)/(S0 * sigma * sqrt(T-t))
gamma3 <- dnorm(d1_2)/(S0 * sigma * sqrt(T-t))
gamma_portfolio <- -gamma1 + 2*gamma2 - gamma3
#vega of portfolio
vega1 <- S0 * dnorm (d1_1) * sqrt(T-t)
vega2 <- S0 * dnorm (d1_2) * sqrt(T-t)
vega3 <- S0 * dnorm (d1_3) * sqrt(T-t)
vega_portfolio <- -vega1 + 2*vega2 - vega3
1/(sqrt(2* pi)*exp(-d1_1)^2/2)
dnorm(d1_1)
#theta of portfolio
theta1 <- -(S0 * dnorm(d1_1)*sigma)/(2 * sqrt(T-t)) + r*K1 *exp(-r * (T-t))*pnorm(-d2_1)
theta2 <- -(S0 * dnorm(d1_2)*sigma)/(2 * sqrt(T-t)) + r*K2 *exp(-r * (T-t))*pnorm(-d2_2)
theta3 <- -(S0 * dnorm(d1_3)*sigma)/(2 * sqrt(T-t)) + r*K3 *exp(-r * (T-t))*pnorm(-d2_3)
theta_portfolio <- -theta1 +2*theta2 - theta3
#rho of portfolio
rho1 <- -K1 * exp(-r * (T-t)) * pnorm(-d2_1)
rho2 <- -K2 * exp(-r * (T-t)) * pnorm(-d2_2)
rho3 <- -K3 * exp(-r * (T-t)) * pnorm(-d2_3)
rho_portfolio <- -rho1 + 2*rho2 - rho3
delta_portfolio
gamma_portfolio
vega_portfolio
theta_portfolio
rho_portfolio
#part b
t2 <- seq(0,1, 1/12)
St <- c(S0, 2131.77, 2572.13,3103.46, 3744.54,4518.05, 5451.34,6577.43, 7936.13,6577.43, 5451.34,4518.05, 3744.54)
data.frame(t2,St)
library(readxl)
Production <- read_excel("C:/Users/20182102/OneDrive - TU Eindhoven/Universiteit/2020-2021/BEP/Production.xlsx")
View(Production)
Table(Production)
table(Production)
table(Production[4])
Production[4]
plot(table(Production[4]))
sort(table(Production[4]))
plot(sort(table(Production[4])))
plot(sort(table(Production[3])))
sort(table(Production[3]))
sort(table(Production[3]))
load("C:/Users/20182102/Downloads/BenAndJerry.RData")
Unit.price <- c(BenAndJerry$price_paid_deal + BenAndJerry$price_paid_non_deal)
BenAndJerry$Unit.price <- Unit.price
View(BenAndJerry)
?tapply
aggregate(BenAndJerry[, 'Unit.price'], list(BenAndJerry$flavor_descr ), mean)
?aggregate
aggregate(unit.price ~ flavor_descr, FUN = mean, data = BenAndJerry)
aggregate(Unit.price ~ flavor_descr, FUN = mean, data = BenAndJerry)
tab_flavours <- aggregate(Unit.price ~ flavor_descr, FUN = mean, data = BenAndJerry)
?subset
subset(BenAndJerry, price_paid_non_deal > 0, select = c(price_paid_non_deal, flavor_descr))
subset(BenAndJerry, price_paid_deal > 0, select = c(price_paid_deal, flavor_descr))
subset(BenAndJerry, price_paid_non_deal > 0, select = c(flavor_descr, price_paid_non_deal ))
subset(BenAndJerry, price_paid_deal > 0, select = c(flavor_descr, price_paid_deal))
non_deals <- subset(BenAndJerry, price_paid_non_deal > 0, select = c(flavor_descr, price_paid_non_deal ))
deals <- subset(BenAndJerry, price_paid_deal > 0, select = c(flavor_descr, price_paid_deal))
View(non_deals)
View(non_deals)
tab_promo <- aggregate(price_paid_deal ~ flavor_descr, FUN = mean, data = deals)
tab_promo
tab_promo <- aggregate(price_paid_deal ~ flavor_descr, FUN = mean, data = deals)
tab_nopromo <- aggregate(price_paid_non_deal ~ flavor_descr, FUN = mean, data = non_deals)
tab_promo[2] - tab_nopromo[2]
tab_promo[,2] - tab_nopromo[,2]
tab_promo
tab_promo[,2]
tab_promo$nopromo <- tab_nopromo[,2]
tab_promo
tab_nopromo
x<- rep(0,50)
for(i in 1: 50){
if (tab_promo[i,1]== tab_nopromo[i,1]){
x[i] <- tab_nopromo[i, 2] - tab_nopromo}
else {
x[i] <- tab_nopromo[i]
}
}
x<- rep(0,50)
for(i in 1: 50){
if (tab_promo[i,1]== tab_nopromo[i,1]){
x[i] <- tab_nopromo[i, 2] - tab_nopromo[i,2]}
else {
x[i] <- tab_nopromo[i]
}
}
x<- rep(0,50)
for(i in 1: 50){
if (tab_promo[i,1]== tab_nopromo[i,1]){
x[i] <- tab_nopromo[i, 2] - tab_nopromo[i,2]}
else {
x[i] <- tab_nopromo[i,2]
}
}
for(i in 1: 50){
if (tab_promo[i,1]== tab_nopromo[i,1]){
x[i] <- tab_nopromo[i, 2] - tab_nopromo[i,2]}
else {
x[i] <- tab_nopromo[i,2]
}
}
View(deals)
View(non_deals)
View(tab_nopromo)
View(tab_promo)
tab_flavours
aggregate(price_paid_deal ~ flavor_descr, FUN = mean, data = BenAndJerry)
aggregate(price_paid_deal ~ flavor_descr, data = BenAndJerry)
subset(BenAndJerry, price_paid_non_deal +> 0, select = c(flavor_descr, price_paid_non_deal ))
subset(BenAndJerry, price_paid_non_deal => 0, select = c(flavor_descr, price_paid_non_deal ))
subset(BenAndJerry, price_paid_non_deal >= 0, select = c(flavor_descr, price_paid_non_deal ))
aggregate(price_paid_deal ~ flavor_descr, FUN = sum, data = subset(BenAndJerry, price_paid_non_deal >= 0, select = c(flavor_descr, price_paid_non_deal )))
aggregate(price_paid_non_deal ~ flavor_descr, FUN = sum, data = subset(BenAndJerry, price_paid_non_deal >= 0, select = c(flavor_descr, price_paid_non_deal )))
non_deals2<-  subset(BenAndJerry, price_paid_non_deal >= 0, select = c(flavor_descr, price_paid_non_deal ))
non_check <- aggregate(price_paid_non_deal ~ flavor_descr, FUN =sum, data = non_deals2)
non_check
aggregate(price_paid_non_deal ~ flavor_descr, FUN =count, data = non_deals2)
tab_promo
tab_nopromo
table(BenAndJerry)
table(BenAndJerry$flavor_descr)
tab_freq = table(BenAndJerry$flavor_descr)
library(dplyr)
library(dplyr)
library(dplyr)
BenAndJerry%>%group_by(flavor_descr, male_head_birth, female_head_birth)%>%count()
library(tidyverse)
BenAndJerry%>%group_by(flavor_descr, male_head_birth, female_head_birth)%>%count()
library(tidyverse)
BenAndJerry%>%
group_by(flavor_descr, male_head_birth, female_head_birth)%>%count()
BenAndJerry%>%
group_by(flavor_descr, male_head_birth, female_head_birth)%>%
x<- rep(0,50)
library(tidyverse)
BenAndJerry%>%
group_by(flavor_descr, male_head_birth, female_head_birth)%>%
x<- rep(0,50)
BenAndJerry%>%
group_by(flavor_descr, male_head_birth)%>%
x<- rep(0,50)
library(tidyverse)
aggregate(Unit.price ~ flavor_descr, FUN = mean, subset = is.na(promotion_type), data = BenAndJerry)
tab_nopromo
load("C:/Users/20182102/Downloads/LightBeer.RData")
View(LightBeer)
aggregate(Unit.price ~ beer_brand + container_description, FUN=mean, data = LightBeer)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == FALSE FUN=mean, data = LightBeer)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == FALSE, FUN=mean, data = LightBeer)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == 'FALSE', FUN=mean, data = LightBeer)
Unit.price <- (LightBeer$beer_spend1.11)/((LightBeer$beer_floz29.57353)*0.001)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == 'FALSE', FUN=mean, data = LightBeer)
Unit.price <- (LightBeer$beer_spend1.11)/((LightBeer$beer_floz*29.57353)*0.001)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == 'FALSE', FUN=mean, data = LightBeer)
Unit.price <- (LightBeer$beer_spend*1.11)/((LightBeer$beer_floz*29.57353)*0.001)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == 'FALSE', FUN=mean, data = LightBeer)
round(5.3213123, digits = 2)
averagebeerprice <- aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == 'FALSE', FUN=mean, data = LightBeer)
print.data.frame(averagebeerprice, digits = 3)
print.data.frame(averagebeerprice, digits = 2)
LightBeer$Unit.price <- Unit.price
LightBeer$beer_brand[beer_brand == 'Miller lite']
LightBeer[LightBeer$beer_brand, 'Miller lite']
LightBeer[LightBeer$beer_brand, 'MILLER LITE']
gc()
x + 6
x <- 7
x + 6
u <- 1.5
d <- 0.5
w1 <- 6
w2 <- 15
u <- 1.5
d <- 0.5
w1 <- 6
w2 <- 15
q <- function(r){
print(1 + r - d)
}
q(2)
#Steps in order to fix the dataset
#Load Dataset
# data<-read.csv("datasets/MI.data")
data <- read.table('datasets/MI.data', sep = ',')
data[]<-lapply(data, function(x) as.numeric(as.character(x))) #Force all datatypes to be numeric
y <- data[c(122)]#Output
#Remove variables that are useless
data <- data[-c(1, 95, 102, 105, 112:121, 123, 124)]
#Remove variables that have more than 25% missing values
data<-data[, which(colMeans(!is.na(data)) > 0.25)]
#Fix NaN values: Real variables: Mean, Binary variables: Mode
getmode <- function(v) { #Function for the mode
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
data_na <- data
for(i in 1:ncol(data)) {
if (is.na(getmode (data_na[ , i]))){ #If mode is NA, most likely that it is real value, mean is okay
data_na[ , i][is.na(data_na[ , i])] <- mean(data_na[ , i], na.rm = TRUE)
}
else{ #Take for the ordinal and binary
data_na[ , i][is.na(data_na[ , i])] <- getmode(data_na[ , i])
}
}
#Normalization/standardization of real values
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
data_norm <- as.data.frame(lapply(data_na, min_max_norm))
#Remove variables with correlation matrix (real variables and ordinal data)
data_binary <- data.frame()
data_real <- data.frame()
for (column in data_norm){
if (length(unique(column)) == 2){
print(column)
# print(colnames(data_norm[column]))
}
}
#Remove variables with Chi-Squared test (Binary variables)
#Optional
#One hot encoding of Ordinal values
#
for (column in data_norm){
if (length(unique(column)) == 2){
print(colnames(data_norm[column]))
}
}
#Steps in order to fix the dataset
#Load Dataset
# data<-read.csv("datasets/MI.data")
data <- read.table('datasets/MI.data', sep = ',')
data[]<-lapply(data, function(x) as.numeric(as.character(x))) #Force all datatypes to be numeric
y <- data[c(122)]#Output
#Remove variables that are useless
data <- data[-c(1, 95, 102, 105, 112:121, 123, 124)]
#Remove variables that have more than 25% missing values
data<-data[, which(colMeans(!is.na(data)) > 0.25)]
#Fix NaN values: Real variables: Mean, Binary variables: Mode
getmode <- function(v) { #Function for the mode
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
data_na <- data
for(i in 1:ncol(data)) {
if (is.na(getmode (data_na[ , i]))){ #If mode is NA, most likely that it is real value, mean is okay
data_na[ , i][is.na(data_na[ , i])] <- mean(data_na[ , i], na.rm = TRUE)
}
else{ #Take for the ordinal and binary
data_na[ , i][is.na(data_na[ , i])] <- getmode(data_na[ , i])
}
}
#Normalization/standardization of real values
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
data_norm <- as.data.frame(lapply(data_na, min_max_norm))
#Remove variables with correlation matrix (real variables and ordinal data)
data_binary <- data.frame()
data_real <- data.frame()
for (column in data_norm){
if (length(unique(column)) == 2){
print(colnames(data_norm[column]))
}
}
#Remove variables with Chi-Squared test (Binary variables)
#Optional
#One hot encoding of Ordinal values
#
#Remove variables with correlation matrix (real variables and ordinal data)
data_binary <- data.frame()
data_real <- data.frame()
for (column in data_norm){
if (length(unique(column)) == 2){
print(column)
# print(colnames(data_norm[column]))
}
}
data_norm <- as.data.frame(lapply(data_na, min_max_norm))
#Steps in order to fix the dataset
#Load Dataset
# data<-read.csv("datasets/MI.data")
data <- read.table('datasets/MI.data', sep = ',')
data[]<-lapply(data, function(x) as.numeric(as.character(x))) #Force all datatypes to be numeric
y <- data[c(122)]#Output
#Remove variables that are useless
data <- data[-c(1, 95, 102, 105, 112:121, 123, 124)]
#Remove variables that have more than 25% missing values
data<-data[, which(colMeans(!is.na(data)) > 0.25)]
#Fix NaN values: Real variables: Mean, Binary variables: Mode
getmode <- function(v) { #Function for the mode
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
data_na <- data
for(i in 1:ncol(data)) {
if (is.na(getmode (data_na[ , i]))){ #If mode is NA, most likely that it is real value, mean is okay
data_na[ , i][is.na(data_na[ , i])] <- mean(data_na[ , i], na.rm = TRUE)
}
else{ #Take for the ordinal and binary
data_na[ , i][is.na(data_na[ , i])] <- getmode(data_na[ , i])
}
}
#Normalization/standardization of real values
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
data_norm <- as.data.frame(lapply(data_na, min_max_norm))
#Remove variables with correlation matrix (real variables and ordinal data)
# data_binary <- data.frame()
# data_real <- data.frame()
# for (column in data_norm){
#   if (length(unique(column)) == 2){
#     print(column)
#     # print(colnames(data_norm[column]))
#   }
# }
#Remove variables with Chi-Squared test (Binary variables)
#Optional
#One hot encoding of Ordinal values
#
#Steps in order to fix the dataset
#Load Dataset
# data<-read.csv("datasets/MI.data")
data <- read.table('datasets/MI.data', sep = ',')
setwd("~/Github/SMDM")
#Steps in order to fix the dataset
#Load Dataset
# data<-read.csv("datasets/MI.data")
data <- read.table('datasets/MI.data', sep = ',')
data[]<-lapply(data, function(x) as.numeric(as.character(x))) #Force all datatypes to be numeric
y <- data[c(122)]#Output
#Remove variables that are useless
data <- data[-c(1, 95, 102, 105, 112:121, 123, 124)]
#Remove variables that have more than 25% missing values
data<-data[, which(colMeans(!is.na(data)) > 0.25)]
#Fix NaN values: Real variables: Mean, Binary variables: Mode
getmode <- function(v) { #Function for the mode
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
data_na <- data
for(i in 1:ncol(data)) {
if (is.na(getmode (data_na[ , i]))){ #If mode is NA, most likely that it is real value, mean is okay
data_na[ , i][is.na(data_na[ , i])] <- mean(data_na[ , i], na.rm = TRUE)
}
else{ #Take for the ordinal and binary
data_na[ , i][is.na(data_na[ , i])] <- getmode(data_na[ , i])
}
}
#Normalization/standardization of real values
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
data_norm <- as.data.frame(lapply(data_na, min_max_norm))
#Remove variables with correlation matrix (real variables and ordinal data)
# data_binary <- data.frame()
# data_real <- data.frame()
# for (column in data_norm){
#   if (length(unique(column)) == 2){
#     print(column)
#     # print(colnames(data_norm[column]))
#   }
# }
#Remove variables with Chi-Squared test (Binary variables)
#Optional
#One hot encoding of Ordinal values
#
data_binary <- data.frame()
data_real <- data.frame()
for (column in data_norm){
if (length(unique(column)) == 2){
print(column)
# print(colnames(data_norm[column]))
}
}
for (column in data_norm){
if (length(unique(column)) == 2){
# print(colnames(data_norm[column]))
}
}
for (column in data_norm){
if (length(unique(column)) == 2){
print(colnames(data_norm[column]))
}
}
View(data_norm)
#Remove variables with correlation matrix (real variables and ordinal data)
data_binary <- data.frame()
data_real <- data.frame()
for (column in 1:length(data_norm)){
if (length(unique(column)) == 2){
data_binary[colnames(data_norm[column])] <- data_norm[colnames(data_norm[column])]
}
}
View(data_binary)
#Remove variables with correlation matrix (real variables and ordinal data)
data_binary <- data.frame()
data_real <- data.frame()
for (column in 1:length(data_norm)){
if (length(unique(column)) == 2){
print('test')
data_binary[colnames(data_norm[column])] <- data_norm[colnames(data_norm[column])]
}
}
#Remove variables with correlation matrix (real variables and ordinal data)
data_binary <- data.frame()
data_real <- data.frame()
for (column in 1:length(data_norm)){
if (length(unique(colnames(data_norm[column]))) == 2){
print('test')
data_binary[colnames(data_norm[column])] <- data_norm[colnames(data_norm[column])]
}
}
for (column in 1:length(data_norm)){
print(column)
if (length(unique(colnames(data_norm[column]))) == 2){
print('test')
data_binary[colnames(data_norm[column])] <- data_norm[colnames(data_norm[column])]
}
}
View(data_norm)
#Remove variables with correlation matrix (real variables and ordinal data)
data_binary <- data.frame()
data_real <- data.frame()
for (column in 1:length(data_norm)){
print(data_norm[colnames(data_norm[column])])
if (length(unique(data_norm[colnames(data_norm[column])])) == 2){
print('test')
data_binary[colnames(data_norm[column])] <- data_norm[colnames(data_norm[column])]
}
}
for (column in 1:length(data_norm)){
print(unique(data_norm[colnames(data_norm[column])]))
if (length(unique(data_norm[colnames(data_norm[column])])) == 2){
print('test')
data_binary[colnames(data_norm[column])] <- data_norm[colnames(data_norm[column])]
}
}
for (column in 1:length(data_norm)){
print(length(unique(data_norm[colnames(data_norm[column])])))
if (length(unique(data_norm[colnames(data_norm[column])])) == 2){
print('test')
data_binary[colnames(data_norm[column])] <- data_norm[colnames(data_norm[column])]
}
}
for (column in data_norm){
print(column)
if (length(unique(column)) == 2){
print('test')
}
}
for (column in data_norm){
if (length(unique(column)) == 2){
data_binary <- cbind(data_binary, column)
}
}
#Remove variables with correlation matrix (real variables and ordinal data)
data_binary <- data.frame()
data_real <- data.frame()
for (column in data_norm){
if (length(unique(column)) == 2){
data_binary[i] <- column
i <- i+1
}
}
i<- 0
for (column in data_norm){
if (length(unique(column)) == 2){
data_binary[i] <- column
i <- i+1
}
}
#Remove variables with correlation matrix (real variables and ordinal data)
data_binary <- data.frame()
data_real <- data.frame()
for (column in 1:length(data_norm)){
if (length(unique(data_norm[[column]])) == 2){
data_binary[colnames(data_norm[column])] <- data_norm[data_norm[column]]
}
}
#Remove variables with correlation matrix (real variables and ordinal data)
data_binary <- data.frame()
data_real <- data.frame()
for (column in 1:length(data_norm)){
if (length(unique(data_norm[[column]])) == 2){
data_binary[colnames(data_norm[column])] <- data_norm[column]
}
}
for (column in 1:length(data_norm)){
print(data_norm[[column]])
# if (length(unique(data_norm[[column]])) == 2){
#   data_binary[colnames(data_norm[column])] <- data_norm[column]
}
#Remove variables with correlation matrix (real variables and ordinal data)
data_binary <- data.frame()
data_real <- data.frame()
for (column in 1:length(data_norm)){
#Remove variables with correlation matrix (real variables and ordinal data)
data_binary <- data.frame()
data_real <- data.frame()
