Time <- 1
d1_1
#option 1
d1_1 <- (1/(sigma*sqrt(Time-t)))*(log(S0/K1)+(r+(sigma^2)/2)*(Time-t))
d2_1 <- d1_1 - sigma*sqrt(Time-t)
price_put1 <- pnorm(-d2_1)*K1*exp(-r*(Time-t))-pnorm(-d1_1)*S0
#option 2
d1_2 <- (1/(sigma*sqrt(Time-t)))*(log(S0/K2)+(r+(sigma^2)/2)*(Time-t))
d2_2 <- d1_2 - sigma*sqrt(Time-t)
price_put2 <- pnorm(-d2_2)*K2*exp(-r*(Time-t))-pnorm(-d1_2)*S0
#option 3
d1_3 <- (1/(sigma*sqrt(Time-t)))*(log(S0/K3)+(r+(sigma^2)/2)*(Time-t))
d2_3 <- d1_3 - sigma*sqrt(Time-t)
price_put3 <- pnorm(-d2_3)*K3*exp(-r*(Time-t))-pnorm(-d1_3)*S0
#part a
#delta of portfolio
delta1 <- -pnorm(-d1_1)
delta2 <- -pnorm(-d1_2)
delta3 <- -pnorm(-d1_3)
delta_portfolio <- -delta1 + 2* delta2 - delta3
#gamma of portfolio
gamma1 <- dnorm(d1_1)/(S0 * sigma * sqrt(T-t))
gamma2 <- dnorm(d1_3)/(S0 * sigma * sqrt(T-t))
gamma3 <- dnorm(d1_2)/(S0 * sigma * sqrt(T-t))
gamma_portfolio <- -gamma1 + 2*gamma2 - gamma3
#vega of portfolio
vega1 <- S0 * dnorm (d1_1) * sqrt(T-t)
vega2 <- S0 * dnorm (d1_2) * sqrt(T-t)
vega3 <- S0 * dnorm (d1_3) * sqrt(T-t)
vega_portfolio <- -vega1 + 2*vega2 - vega3
1/(sqrt(2* pi)*exp(-d1_1)^2/2)
dnorm(d1_1)
#theta of portfolio
theta1 <- -(S0 * dnorm(d1_1)*sigma)/(2 * sqrt(T-t)) + r*K1 *exp(-r * (T-t))*pnorm(-d2_1)
theta2 <- -(S0 * dnorm(d1_2)*sigma)/(2 * sqrt(T-t)) + r*K2 *exp(-r * (T-t))*pnorm(-d2_2)
theta3 <- -(S0 * dnorm(d1_3)*sigma)/(2 * sqrt(T-t)) + r*K3 *exp(-r * (T-t))*pnorm(-d2_3)
theta_portfolio <- -theta1 +2*theta2 - theta3
#rho of portfolio
rho1 <- -K1 * exp(-r * (T-t)) * pnorm(-d2_1)
rho2 <- -K2 * exp(-r * (T-t)) * pnorm(-d2_2)
rho3 <- -K3 * exp(-r * (T-t)) * pnorm(-d2_3)
rho_portfolio <- -rho1 + 2*rho2 - rho3
delta_portfolio
gamma_portfolio
vega_portfolio
theta_portfolio
rho_portfolio
#part b
t2 <- seq(0,1, 1/12)
St <- c(S0, 2131.77, 2572.13,3103.46, 3744.54,4518.05, 5451.34,6577.43, 7936.13,6577.43, 5451.34,4518.05, 3744.54)
data.frame(t2,St)
#parameters
v <- 1.02604
sigma <- 0.650496
r <- (v + 0.5*sigma^2)
S0 <- 1766.8
K1 <- 1700
K2 <- 2000
K3 <- 2300
St <- seq(0, 2600, 1)
butterfly <- function(){
-pmax(K1-St,0) + 2* pmax(K2-St,0)- pmax(K3-St,0)
}
#using the Black-Scholes model, compute the price of the 1 year European call option
t <- 0
Time <- 1
d1_1
#option 1
d1_1 <- (1/(sigma*sqrt(Time-t)))*(log(S0/K1)+(r+(sigma^2)/2)*(Time-t))
d2_1 <- d1_1 - sigma*sqrt(Time-t)
price_put1 <- pnorm(-d2_1)*K1*exp(-r*(Time-t))-pnorm(-d1_1)*S0
#option 2
d1_2 <- (1/(sigma*sqrt(Time-t)))*(log(S0/K2)+(r+(sigma^2)/2)*(Time-t))
d2_2 <- d1_2 - sigma*sqrt(Time-t)
price_put2 <- pnorm(-d2_2)*K2*exp(-r*(Time-t))-pnorm(-d1_2)*S0
#option 3
d1_3 <- (1/(sigma*sqrt(Time-t)))*(log(S0/K3)+(r+(sigma^2)/2)*(Time-t))
d2_3 <- d1_3 - sigma*sqrt(Time-t)
price_put3 <- pnorm(-d2_3)*K3*exp(-r*(Time-t))-pnorm(-d1_3)*S0
#part a
#delta of portfolio
delta1 <- -pnorm(-d1_1)
delta2 <- -pnorm(-d1_2)
delta3 <- -pnorm(-d1_3)
delta_portfolio <- -delta1 + 2* delta2 - delta3
#gamma of portfolio
gamma1 <- dnorm(d1_1)/(S0 * sigma * sqrt(T-t))
gamma2 <- dnorm(d1_3)/(S0 * sigma * sqrt(T-t))
gamma3 <- dnorm(d1_2)/(S0 * sigma * sqrt(T-t))
gamma_portfolio <- -gamma1 + 2*gamma2 - gamma3
#vega of portfolio
vega1 <- S0 * dnorm (d1_1) * sqrt(T-t)
vega2 <- S0 * dnorm (d1_2) * sqrt(T-t)
vega3 <- S0 * dnorm (d1_3) * sqrt(T-t)
vega_portfolio <- -vega1 + 2*vega2 - vega3
1/(sqrt(2* pi)*exp(-d1_1)^2/2)
dnorm(d1_1)
#theta of portfolio
theta1 <- -(S0 * dnorm(d1_1)*sigma)/(2 * sqrt(T-t)) + r*K1 *exp(-r * (T-t))*pnorm(-d2_1)
theta2 <- -(S0 * dnorm(d1_2)*sigma)/(2 * sqrt(T-t)) + r*K2 *exp(-r * (T-t))*pnorm(-d2_2)
theta3 <- -(S0 * dnorm(d1_3)*sigma)/(2 * sqrt(T-t)) + r*K3 *exp(-r * (T-t))*pnorm(-d2_3)
theta_portfolio <- -theta1 +2*theta2 - theta3
#rho of portfolio
rho1 <- -K1 * exp(-r * (T-t)) * pnorm(-d2_1)
rho2 <- -K2 * exp(-r * (T-t)) * pnorm(-d2_2)
rho3 <- -K3 * exp(-r * (T-t)) * pnorm(-d2_3)
rho_portfolio <- -rho1 + 2*rho2 - rho3
delta_portfolio
gamma_portfolio
vega_portfolio
theta_portfolio
rho_portfolio
#part b
t2 <- seq(0,1, 1/12)
St <- c(S0, 2131.77, 2572.13,3103.46, 3744.54,4518.05, 5451.34,6577.43, 7936.13,6577.43, 5451.34,4518.05, 3744.54)
data.frame(t2,St)
library(readxl)
Production <- read_excel("C:/Users/20182102/OneDrive - TU Eindhoven/Universiteit/2020-2021/BEP/Production.xlsx")
View(Production)
Table(Production)
table(Production)
table(Production[4])
Production[4]
plot(table(Production[4]))
sort(table(Production[4]))
plot(sort(table(Production[4])))
plot(sort(table(Production[3])))
sort(table(Production[3]))
sort(table(Production[3]))
load("C:/Users/20182102/Downloads/BenAndJerry.RData")
Unit.price <- c(BenAndJerry$price_paid_deal + BenAndJerry$price_paid_non_deal)
BenAndJerry$Unit.price <- Unit.price
View(BenAndJerry)
?tapply
aggregate(BenAndJerry[, 'Unit.price'], list(BenAndJerry$flavor_descr ), mean)
?aggregate
aggregate(unit.price ~ flavor_descr, FUN = mean, data = BenAndJerry)
aggregate(Unit.price ~ flavor_descr, FUN = mean, data = BenAndJerry)
tab_flavours <- aggregate(Unit.price ~ flavor_descr, FUN = mean, data = BenAndJerry)
?subset
subset(BenAndJerry, price_paid_non_deal > 0, select = c(price_paid_non_deal, flavor_descr))
subset(BenAndJerry, price_paid_deal > 0, select = c(price_paid_deal, flavor_descr))
subset(BenAndJerry, price_paid_non_deal > 0, select = c(flavor_descr, price_paid_non_deal ))
subset(BenAndJerry, price_paid_deal > 0, select = c(flavor_descr, price_paid_deal))
non_deals <- subset(BenAndJerry, price_paid_non_deal > 0, select = c(flavor_descr, price_paid_non_deal ))
deals <- subset(BenAndJerry, price_paid_deal > 0, select = c(flavor_descr, price_paid_deal))
View(non_deals)
View(non_deals)
tab_promo <- aggregate(price_paid_deal ~ flavor_descr, FUN = mean, data = deals)
tab_promo
tab_promo <- aggregate(price_paid_deal ~ flavor_descr, FUN = mean, data = deals)
tab_nopromo <- aggregate(price_paid_non_deal ~ flavor_descr, FUN = mean, data = non_deals)
tab_promo[2] - tab_nopromo[2]
tab_promo[,2] - tab_nopromo[,2]
tab_promo
tab_promo[,2]
tab_promo$nopromo <- tab_nopromo[,2]
tab_promo
tab_nopromo
x<- rep(0,50)
for(i in 1: 50){
if (tab_promo[i,1]== tab_nopromo[i,1]){
x[i] <- tab_nopromo[i, 2] - tab_nopromo}
else {
x[i] <- tab_nopromo[i]
}
}
x<- rep(0,50)
for(i in 1: 50){
if (tab_promo[i,1]== tab_nopromo[i,1]){
x[i] <- tab_nopromo[i, 2] - tab_nopromo[i,2]}
else {
x[i] <- tab_nopromo[i]
}
}
x<- rep(0,50)
for(i in 1: 50){
if (tab_promo[i,1]== tab_nopromo[i,1]){
x[i] <- tab_nopromo[i, 2] - tab_nopromo[i,2]}
else {
x[i] <- tab_nopromo[i,2]
}
}
for(i in 1: 50){
if (tab_promo[i,1]== tab_nopromo[i,1]){
x[i] <- tab_nopromo[i, 2] - tab_nopromo[i,2]}
else {
x[i] <- tab_nopromo[i,2]
}
}
View(deals)
View(non_deals)
View(tab_nopromo)
View(tab_promo)
tab_flavours
aggregate(price_paid_deal ~ flavor_descr, FUN = mean, data = BenAndJerry)
aggregate(price_paid_deal ~ flavor_descr, data = BenAndJerry)
subset(BenAndJerry, price_paid_non_deal +> 0, select = c(flavor_descr, price_paid_non_deal ))
subset(BenAndJerry, price_paid_non_deal => 0, select = c(flavor_descr, price_paid_non_deal ))
subset(BenAndJerry, price_paid_non_deal >= 0, select = c(flavor_descr, price_paid_non_deal ))
aggregate(price_paid_deal ~ flavor_descr, FUN = sum, data = subset(BenAndJerry, price_paid_non_deal >= 0, select = c(flavor_descr, price_paid_non_deal )))
aggregate(price_paid_non_deal ~ flavor_descr, FUN = sum, data = subset(BenAndJerry, price_paid_non_deal >= 0, select = c(flavor_descr, price_paid_non_deal )))
non_deals2<-  subset(BenAndJerry, price_paid_non_deal >= 0, select = c(flavor_descr, price_paid_non_deal ))
non_check <- aggregate(price_paid_non_deal ~ flavor_descr, FUN =sum, data = non_deals2)
non_check
aggregate(price_paid_non_deal ~ flavor_descr, FUN =count, data = non_deals2)
tab_promo
tab_nopromo
table(BenAndJerry)
table(BenAndJerry$flavor_descr)
tab_freq = table(BenAndJerry$flavor_descr)
library(dplyr)
library(dplyr)
library(dplyr)
BenAndJerry%>%group_by(flavor_descr, male_head_birth, female_head_birth)%>%count()
library(tidyverse)
BenAndJerry%>%group_by(flavor_descr, male_head_birth, female_head_birth)%>%count()
library(tidyverse)
BenAndJerry%>%
group_by(flavor_descr, male_head_birth, female_head_birth)%>%count()
BenAndJerry%>%
group_by(flavor_descr, male_head_birth, female_head_birth)%>%
x<- rep(0,50)
library(tidyverse)
BenAndJerry%>%
group_by(flavor_descr, male_head_birth, female_head_birth)%>%
x<- rep(0,50)
BenAndJerry%>%
group_by(flavor_descr, male_head_birth)%>%
x<- rep(0,50)
library(tidyverse)
aggregate(Unit.price ~ flavor_descr, FUN = mean, subset = is.na(promotion_type), data = BenAndJerry)
tab_nopromo
load("C:/Users/20182102/Downloads/LightBeer.RData")
View(LightBeer)
aggregate(Unit.price ~ beer_brand + container_description, FUN=mean, data = LightBeer)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == FALSE FUN=mean, data = LightBeer)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == FALSE, FUN=mean, data = LightBeer)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == 'FALSE', FUN=mean, data = LightBeer)
Unit.price <- (LightBeer$beer_spend1.11)/((LightBeer$beer_floz29.57353)*0.001)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == 'FALSE', FUN=mean, data = LightBeer)
Unit.price <- (LightBeer$beer_spend1.11)/((LightBeer$beer_floz*29.57353)*0.001)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == 'FALSE', FUN=mean, data = LightBeer)
Unit.price <- (LightBeer$beer_spend*1.11)/((LightBeer$beer_floz*29.57353)*0.001)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == 'FALSE', FUN=mean, data = LightBeer)
round(5.3213123, digits = 2)
averagebeerprice <- aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == 'FALSE', FUN=mean, data = LightBeer)
print.data.frame(averagebeerprice, digits = 3)
print.data.frame(averagebeerprice, digits = 2)
LightBeer$Unit.price <- Unit.price
LightBeer$beer_brand[beer_brand == 'Miller lite']
LightBeer[LightBeer$beer_brand, 'Miller lite']
LightBeer[LightBeer$beer_brand, 'MILLER LITE']
gc()
x + 6
x <- 7
x + 6
u <- 1.5
d <- 0.5
w1 <- 6
w2 <- 15
u <- 1.5
d <- 0.5
w1 <- 6
w2 <- 15
q <- function(r){
print(1 + r - d)
}
q(2)
r.version()
R.version()
R.version
getwd()
setwd("~/Github/SMDM")
#install.packages(c("cluster", "factoextra","fpc"))
#install.packages('fossil')
library(cluster)
library(factoextra)
library(fossil)
data <- readRDS("datasets/preprocessed.RDS")
y <- data$V122
data$V122 <- NULL
#See what the difference methods can do
mycluster <- function(x, k) list(cluster=cutree(hclust(dist(x), method = "average"),k=k))
gap_stat <- clusGap(data, FUN = mycluster, K.max = 8, B = 500)
fviz_gap_stat(gap_stat) # "firstSEmax"
#New way
#aggolomerative
res.agnes <- agnes(x = data,
metric = "euclidean",
method = "average")
#Divide in two groups
grp <- cutree(res.agnes, k =2)
#Loop through everything
methods <- list("average", "single", "complete", "ward")
for (method in methods){
res.agnes <- agnes(x = data,
metric = "euclidean",
method = method)
grp <- cutree(res.agnes, k =2)
rand_index <- rand.index(grp,y)
print(method)
print(rand_index)
}
#Divisive
res.diana <- diana(x = data,
metric = "euclidean")
grp <- cutree(res.diana, k =2)
rand_index <- rand.index(grp,y)
# #make dendogram
# fviz_dend(agnes, cex = 0.6, k = 2)
#
# #Make cluster plot
# fviz_cluster(list(data = data, cluster = grp), ellipse.type = "norm")
rand_index
#make dendogram
fviz_dend(agnes, cex = 0.6, k = 2)
#make dendogram
fviz_dend(res.diana, cex = 0.6, k = 2)
#Make cluster plot
fviz_cluster(list(data = data, cluster = grp), ellipse.type = "norm")
setwd("~/Github/SMDM")
# PARTITIONING METHODS
# Install Dependencies
#install.packages("fpc")
#install.packages("dbscan")
#install.packages("factoextra")
#install.packages("cluster")
library("fpc")
library("dbscan")
# Install Dependencies
#install.packages("fpc")
install.packages("dbscan")
# PARTITIONING METHODS
# Install Dependencies
#install.packages("fpc")
# install.packages("dbscan")
#install.packages("factoextra")
#install.packages("cluster")
library("fpc")
library("dbscan")
library("factoextra")
library("cluster")
library(plyr)
library("ggplot2")
# Set seed for reproducibility
set.seed(1)
# Get preprocessed data
data <- readRDS("datasets/preprocessed.RDS")
class<- data$V122
data <- data[,!names(data) %in%
c('V122')]
############################################################################
#                           PARTITION CLUSTERING                           #
############################################################################
######################################
#              K-MEANS               #
######################################
#Find the Optimal Number of Clusters
#Number of Clusters vs. the Total Within Sum of Squares
fviz_nbclust(data, kmeans, method = "wss")
#or this plot it appears that there is a bit of an elbow or “bend” at k = 3 clusters.
#Perform K-Means Clustering with Optimal K
#perform k-means clustering with k = 3 clusters
km <- kmeans(data, centers = 2, nstart = 25)
#view results
km
#plot results of final k-means model
fviz_cluster(km, data = data)
{
kmed_mad<-mapvalues(km$cluster, from = c(1, 2), to = c(0, 1))
table(kmed_mad, class)
}
{
kmed_mad<-mapvalues(km$cluster, from = c(1, 2), to = c(1, 0))
table(kmed_mad, class)
}
#find means of each cluster
aggregate(data, by=list(cluster=km$cluster), mean)
final_data <- cbind(data, cluster = km$cluster)
######################################
#             K-MEDOIDS              #
######################################
fviz_nbclust(data, pam, method = "wss")
#perform k-medoids clustering with k = 7 clusters
kmed <- pam(data, k = 2)
#view results
kmed
#plot results of final k-medoids model
fviz_cluster(kmed, data = data)
{
kmed_mad<-mapvalues(kmed$cluster, from = c(1, 2), to = c(0, 1))
table(kmed_mad, class)
}
{
kmed_mad<-mapvalues(kmed$cluster, from = c(2, 1), to = c(0, 1))
table(kmed, class)
}
#install.packages(c("cluster", "factoextra","fpc"))
#install.packages('fossil')
library(cluster)
library(factoextra)
library(fossil)
data <- readRDS("datasets/preprocessed.RDS")
y <- data$V122
data$V122 <- NULL
# #See what the difference methods can do
# mycluster <- function(x, k) list(cluster=cutree(hclust(dist(x), method = "average"),k=k))
# gap_stat <- clusGap(data, FUN = mycluster, K.max = 8, B = 500)
# fviz_gap_stat(gap_stat) # "firstSEmax"
#New way
#aggolomerative
res.agnes <- agnes(x = data,
metric = "euclidean",
method = "average")
#Divide in two groups
grp <- cutree(res.agnes, k =2)
#Loop through everything
methods <- list("average", "single", "complete", "ward")
for (method in methods){
res.agnes <- agnes(x = data,
metric = "euclidean",
method = method)
grp <- cutree(res.agnes, k =2)
rand_index <- rand.index(grp,y)
print(method)
print(rand_index)
}
#Divisive
res.diana <- diana(x = data,
metric = "euclidean")
grp <- cutree(res.diana, k =2)
rand_index <- rand.index(grp,y)
# #make dendogram
fviz_dend(res.diana, cex = 0.6, k = 2)
#
# #Make cluster plot
# fviz_cluster(list(data = data, cluster = grp), ellipse.type = "norm")
kmed
grp
#Loop through everything
methods <- list("average", "single", "complete", "ward")
for (method in methods){
res.agnes <- agnes(x = data,
metric = "euclidean",
method = method)
grp <- cutree(res.agnes, k =2)
print(table(mapvalues(grp, from = c(2, 1), to = c(0, 1)),y))
print(table(mapvalues(grp, from = c(1, 2), to = c(0, 1)),y))
rand_index <- rand.index(grp,y)
print(method)
print(rand_index)
}
grp <- cutree(res.diana, k =2)
rand_index <- rand.index(grp,y)
print(table(mapvalues(grp, from = c(2, 1), to = c(0, 1)),y))
print(table(mapvalues(grp, from = c(1, 2), to = c(0, 1)),y))
rand_index
# #make dendogram
# fviz_dend(res.diana, cex = 0.6, k = 2)
#
# #Make cluster plot
fviz_cluster(list(data = data, cluster = grp), ellipse.type = "norm")
res.agnes <- agnes(x = data,
metric = "euclidean",
method = "complete")
grp <- cutree(res.agnes, k =4)
grp
y
as.matrix(grp,y)
as.matrix(grp,y)
test <- as.matrix(grp,y)
View(test)
group <- sample(c("Group A", "Group B"), 50, replace = TRUE)
group
group <- sample(c("Group A", "Group B"), 1700, replace = TRUE)
# Create data
set.seed(123)
data1 <- grp
data2 <- y
group <- sample(c("Group A", "Group B"), 1700, replace = TRUE)
df <- data.frame(data1, data2, group)
# Create stacked bar chart
ggplot(df, aes(x = group, fill = factor(data1))) +
geom_bar(aes(y = (..count..)/sum(..count..)), position = "fill") +
geom_bar(aes(y = (..count..)/sum(..count..)), position = "fill", fill = "white") +
geom_bar(aes(y = (..count..)/sum(..count..)), fill = factor(data2), position = "stack") +
xlab("Group") +
ylab("Proportion")
# Create stacked bar chart
ggplot(df, aes(x = group, fill = factor(data1))) +
geom_bar(aes(y = (after_stat(count))/sum(after_stat(count))), position = "fill") +
geom_bar(aes(y = (after_stat(count))/sum(after_stat(count))), position = "fill", fill = "white") +
geom_bar(aes(y = (after_stat(count))/sum(after_stat(count))), fill = factor(data2), position = "stack") +
xlab("Group") +
ylab("Proportion")
df
data1 <- grp
data2 <- y
df <- data.frame(data1, data2)
df
# Create stacked bar chart
ggplot(df, aes(x = group, fill = factor(data1))) +
geom_bar(aes(y = (after_stat(count))/sum(after_stat(count))), position = "fill") +
geom_bar(aes(y = (after_stat(count))/sum(after_stat(count))), position = "fill", fill = "white") +
geom_bar(aes(y = (after_stat(count))/sum(after_stat(count))), fill = factor(data2), position = "stack") +
xlab("Group") +
ylab("Proportion")
ggplot(df) +
geom_bar(position="dodge", stat="identity")
ggplot(df, aes(fill=grp, y=y, x=c(1,2,3,4))) +
geom_bar(position="dodge", stat="identity")
