r <- (v + 0.5*sigma^2)
S0 <- 1766.8
K1 <- 1700
K2 <- 2000
K3 <- 2300
St <- seq(0, 2600, 1)
butterfly <- function(){
-pmax(K1-St,0) + 2* pmax(K2-St,0)- pmax(K3-St,0)
}
#using the Black-Scholes model, compute the price of the 1 year European call option
t <- 0
Time <- 1
d1_1
#option 1
d1_1 <- (1/(sigma*sqrt(Time-t)))*(log(S0/K1)+(r+(sigma^2)/2)*(Time-t))
d2_1 <- d1_1 - sigma*sqrt(Time-t)
price_put1 <- pnorm(-d2_1)*K1*exp(-r*(Time-t))-pnorm(-d1_1)*S0
#option 2
d1_2 <- (1/(sigma*sqrt(Time-t)))*(log(S0/K2)+(r+(sigma^2)/2)*(Time-t))
d2_2 <- d1_2 - sigma*sqrt(Time-t)
price_put2 <- pnorm(-d2_2)*K2*exp(-r*(Time-t))-pnorm(-d1_2)*S0
#option 3
d1_3 <- (1/(sigma*sqrt(Time-t)))*(log(S0/K3)+(r+(sigma^2)/2)*(Time-t))
d2_3 <- d1_3 - sigma*sqrt(Time-t)
price_put3 <- pnorm(-d2_3)*K3*exp(-r*(Time-t))-pnorm(-d1_3)*S0
#part a
#delta of portfolio
delta1 <- -pnorm(-d1_1)
delta2 <- -pnorm(-d1_2)
delta3 <- -pnorm(-d1_3)
delta_portfolio <- -delta1 + 2* delta2 - delta3
#gamma of portfolio
gamma1 <- dnorm(d1_1)/(S0 * sigma * sqrt(T-t))
gamma2 <- dnorm(d1_3)/(S0 * sigma * sqrt(T-t))
gamma3 <- dnorm(d1_2)/(S0 * sigma * sqrt(T-t))
gamma_portfolio <- -gamma1 + 2*gamma2 - gamma3
#vega of portfolio
vega1 <- S0 * dnorm (d1_1) * sqrt(T-t)
vega2 <- S0 * dnorm (d1_2) * sqrt(T-t)
vega3 <- S0 * dnorm (d1_3) * sqrt(T-t)
vega_portfolio <- -vega1 + 2*vega2 - vega3
1/(sqrt(2* pi)*exp(-d1_1)^2/2)
dnorm(d1_1)
#theta of portfolio
theta1 <- -(S0 * dnorm(d1_1)*sigma)/(2 * sqrt(T-t)) + r*K1 *exp(-r * (T-t))*pnorm(-d2_1)
theta2 <- -(S0 * dnorm(d1_2)*sigma)/(2 * sqrt(T-t)) + r*K2 *exp(-r * (T-t))*pnorm(-d2_2)
theta3 <- -(S0 * dnorm(d1_3)*sigma)/(2 * sqrt(T-t)) + r*K3 *exp(-r * (T-t))*pnorm(-d2_3)
theta_portfolio <- -theta1 +2*theta2 - theta3
#rho of portfolio
rho1 <- -K1 * exp(-r * (T-t)) * pnorm(-d2_1)
rho2 <- -K2 * exp(-r * (T-t)) * pnorm(-d2_2)
rho3 <- -K3 * exp(-r * (T-t)) * pnorm(-d2_3)
rho_portfolio <- -rho1 + 2*rho2 - rho3
delta_portfolio
gamma_portfolio
vega_portfolio
theta_portfolio
rho_portfolio
#part b
t2 <- seq(0,1, 1/12)
St <- c(S0, 2131.77, 2572.13,3103.46, 3744.54,4518.05, 5451.34,6577.43, 7936.13,6577.43, 5451.34,4518.05, 3744.54)
data.frame(t2,St)
library(readxl)
Production <- read_excel("C:/Users/20182102/OneDrive - TU Eindhoven/Universiteit/2020-2021/BEP/Production.xlsx")
View(Production)
Table(Production)
table(Production)
table(Production[4])
Production[4]
plot(table(Production[4]))
sort(table(Production[4]))
plot(sort(table(Production[4])))
plot(sort(table(Production[3])))
sort(table(Production[3]))
sort(table(Production[3]))
load("C:/Users/20182102/Downloads/BenAndJerry.RData")
Unit.price <- c(BenAndJerry$price_paid_deal + BenAndJerry$price_paid_non_deal)
BenAndJerry$Unit.price <- Unit.price
View(BenAndJerry)
?tapply
aggregate(BenAndJerry[, 'Unit.price'], list(BenAndJerry$flavor_descr ), mean)
?aggregate
aggregate(unit.price ~ flavor_descr, FUN = mean, data = BenAndJerry)
aggregate(Unit.price ~ flavor_descr, FUN = mean, data = BenAndJerry)
tab_flavours <- aggregate(Unit.price ~ flavor_descr, FUN = mean, data = BenAndJerry)
?subset
subset(BenAndJerry, price_paid_non_deal > 0, select = c(price_paid_non_deal, flavor_descr))
subset(BenAndJerry, price_paid_deal > 0, select = c(price_paid_deal, flavor_descr))
subset(BenAndJerry, price_paid_non_deal > 0, select = c(flavor_descr, price_paid_non_deal ))
subset(BenAndJerry, price_paid_deal > 0, select = c(flavor_descr, price_paid_deal))
non_deals <- subset(BenAndJerry, price_paid_non_deal > 0, select = c(flavor_descr, price_paid_non_deal ))
deals <- subset(BenAndJerry, price_paid_deal > 0, select = c(flavor_descr, price_paid_deal))
View(non_deals)
View(non_deals)
tab_promo <- aggregate(price_paid_deal ~ flavor_descr, FUN = mean, data = deals)
tab_promo
tab_promo <- aggregate(price_paid_deal ~ flavor_descr, FUN = mean, data = deals)
tab_nopromo <- aggregate(price_paid_non_deal ~ flavor_descr, FUN = mean, data = non_deals)
tab_promo[2] - tab_nopromo[2]
tab_promo[,2] - tab_nopromo[,2]
tab_promo
tab_promo[,2]
tab_promo$nopromo <- tab_nopromo[,2]
tab_promo
tab_nopromo
x<- rep(0,50)
for(i in 1: 50){
if (tab_promo[i,1]== tab_nopromo[i,1]){
x[i] <- tab_nopromo[i, 2] - tab_nopromo}
else {
x[i] <- tab_nopromo[i]
}
}
x<- rep(0,50)
for(i in 1: 50){
if (tab_promo[i,1]== tab_nopromo[i,1]){
x[i] <- tab_nopromo[i, 2] - tab_nopromo[i,2]}
else {
x[i] <- tab_nopromo[i]
}
}
x<- rep(0,50)
for(i in 1: 50){
if (tab_promo[i,1]== tab_nopromo[i,1]){
x[i] <- tab_nopromo[i, 2] - tab_nopromo[i,2]}
else {
x[i] <- tab_nopromo[i,2]
}
}
for(i in 1: 50){
if (tab_promo[i,1]== tab_nopromo[i,1]){
x[i] <- tab_nopromo[i, 2] - tab_nopromo[i,2]}
else {
x[i] <- tab_nopromo[i,2]
}
}
View(deals)
View(non_deals)
View(tab_nopromo)
View(tab_promo)
tab_flavours
aggregate(price_paid_deal ~ flavor_descr, FUN = mean, data = BenAndJerry)
aggregate(price_paid_deal ~ flavor_descr, data = BenAndJerry)
subset(BenAndJerry, price_paid_non_deal +> 0, select = c(flavor_descr, price_paid_non_deal ))
subset(BenAndJerry, price_paid_non_deal => 0, select = c(flavor_descr, price_paid_non_deal ))
subset(BenAndJerry, price_paid_non_deal >= 0, select = c(flavor_descr, price_paid_non_deal ))
aggregate(price_paid_deal ~ flavor_descr, FUN = sum, data = subset(BenAndJerry, price_paid_non_deal >= 0, select = c(flavor_descr, price_paid_non_deal )))
aggregate(price_paid_non_deal ~ flavor_descr, FUN = sum, data = subset(BenAndJerry, price_paid_non_deal >= 0, select = c(flavor_descr, price_paid_non_deal )))
non_deals2<-  subset(BenAndJerry, price_paid_non_deal >= 0, select = c(flavor_descr, price_paid_non_deal ))
non_check <- aggregate(price_paid_non_deal ~ flavor_descr, FUN =sum, data = non_deals2)
non_check
aggregate(price_paid_non_deal ~ flavor_descr, FUN =count, data = non_deals2)
tab_promo
tab_nopromo
table(BenAndJerry)
table(BenAndJerry$flavor_descr)
tab_freq = table(BenAndJerry$flavor_descr)
library(dplyr)
library(dplyr)
library(dplyr)
BenAndJerry%>%group_by(flavor_descr, male_head_birth, female_head_birth)%>%count()
library(tidyverse)
BenAndJerry%>%group_by(flavor_descr, male_head_birth, female_head_birth)%>%count()
library(tidyverse)
BenAndJerry%>%
group_by(flavor_descr, male_head_birth, female_head_birth)%>%count()
BenAndJerry%>%
group_by(flavor_descr, male_head_birth, female_head_birth)%>%
x<- rep(0,50)
library(tidyverse)
BenAndJerry%>%
group_by(flavor_descr, male_head_birth, female_head_birth)%>%
x<- rep(0,50)
BenAndJerry%>%
group_by(flavor_descr, male_head_birth)%>%
x<- rep(0,50)
library(tidyverse)
aggregate(Unit.price ~ flavor_descr, FUN = mean, subset = is.na(promotion_type), data = BenAndJerry)
tab_nopromo
load("C:/Users/20182102/Downloads/LightBeer.RData")
View(LightBeer)
aggregate(Unit.price ~ beer_brand + container_description, FUN=mean, data = LightBeer)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == FALSE FUN=mean, data = LightBeer)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == FALSE, FUN=mean, data = LightBeer)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == 'FALSE', FUN=mean, data = LightBeer)
Unit.price <- (LightBeer$beer_spend1.11)/((LightBeer$beer_floz29.57353)*0.001)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == 'FALSE', FUN=mean, data = LightBeer)
Unit.price <- (LightBeer$beer_spend1.11)/((LightBeer$beer_floz*29.57353)*0.001)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == 'FALSE', FUN=mean, data = LightBeer)
Unit.price <- (LightBeer$beer_spend*1.11)/((LightBeer$beer_floz*29.57353)*0.001)
aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == 'FALSE', FUN=mean, data = LightBeer)
round(5.3213123, digits = 2)
averagebeerprice <- aggregate(Unit.price ~ beer_brand + container_descr, subset = promotion == 'FALSE', FUN=mean, data = LightBeer)
print.data.frame(averagebeerprice, digits = 3)
print.data.frame(averagebeerprice, digits = 2)
LightBeer$Unit.price <- Unit.price
LightBeer$beer_brand[beer_brand == 'Miller lite']
LightBeer[LightBeer$beer_brand, 'Miller lite']
LightBeer[LightBeer$beer_brand, 'MILLER LITE']
gc()
x + 6
x <- 7
x + 6
u <- 1.5
d <- 0.5
w1 <- 6
w2 <- 15
u <- 1.5
d <- 0.5
w1 <- 6
w2 <- 15
q <- function(r){
print(1 + r - d)
}
q(2)
r.version()
R.version()
R.version
library(dplyr)
library(tidyr)
library(purrr)
library(ggplot2)
#Steps in order to fix the dataset
#Load Dataset
# data<-read.csv("datasets/MI.data")
data <- read.table('datasets/MI.data', sep = ',')
setwd("~/Github/SMDM")
library(dplyr)
library(tidyr)
library(purrr)
library(ggplot2)
#Steps in order to fix the dataset
#Load Dataset
# data<-read.csv("datasets/MI.data")
data <- read.table('datasets/MI.data', sep = ',')
data[]<-lapply(data, function(x) as.numeric(as.character(x))) #Force all datatypes to be numeric
y <- data[c(122)]#Output
#Remove variables that are useless
data <- data[-c(1, 95, 102, 105, 112:121, 123, 124)]
na_count <-sapply(data, function(y) sum(length(which(is.na(y)))))
hist(na_count, breaks = 10)
#Split the data set in three seperate dataframes based on Binary, real, ordinal
binary_data <- Filter(function(x) all(x %in% c(0, 1, NA)), data)
real_data_only <- data[c('V2', 'V35', 'V36', 'V37', 'V38', 'V84', 'V86', 'V87', 'V88', 'V89' ,'V90', 'V91')]
without_ordinal <- cbind(binary_data, real_data_only)
ordinal_data <- data.frame(data[, -which(names(data) %in% names(without_ordinal))])
#Remove variables that have more than 25% missing values
binary_data<-binary_data[, which(colMeans(!is.na(binary_data)) > 0.75)]
real_data<-real_data_only[, which(colMeans(!is.na(real_data_only)) > 0.75)]
ordinal_data<-ordinal_data[, which(colMeans(!is.na(ordinal_data)) > 0.75)]
#Outlier replacement wit NA for the real values
outlierreplacement <- function(dataframe){
dataframe %>%
map_if(is.numeric, ~ replace(.x, .x %in% boxplot.stats(.x)$out, NA)) %>%
bind_cols
}
real_data <- data.frame(outlierreplacement(real_data))
#Fix NaN values: Real variables: Mean, Binary variables: Mode
getmode <- function(v) { #Function for the mode
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
#For binary and ordinal values, replace NA values with mode
for(i in 1:ncol(binary_data)){
binary_data[ , i][is.na(binary_data[ , i])] <- getmode(binary_data[ , i])
}
for(i in 1:ncol(ordinal_data)){
ordinal_data[ , i][is.na(ordinal_data[ , i])] <- getmode(ordinal_data[ , i])
}
#For real values, the mean
for (i in 1:ncol(real_data)){
real_data[ , i][is.na(real_data[ , i])] <- mean(real_data[ , i], na.rm = TRUE)
}
# Open pdf file
pdf(file= "sample.pdf" )
# create a 2X2 grid
par( mfrow= c(3,3) )
# dim(real_data)
for (i in colnames(real_data)){
real_data %>% pull(i) %>% hist(main = i)
}
library(dplyr)
library(tidyr)
library(purrr)
library(ggplot2)
# # Real/numerical 2, 35, 36, 37, 38, 84, 86, 87, 88, 89. 90, 91  normalizen, anders te veel effect
#
#Steps in order to fix the dataset
#Load Dataset
# data<-read.csv("datasets/MI.data")
data <- read.table('datasets/MI.data', sep = ',')
data[]<-lapply(data, function(x) as.numeric(as.character(x))) #Force all datatypes to be numeric
y <- data[c(122)]#Output
#Remove variables that are useless
data <- data[-c(1, 95, 102, 105, 112:121, 123, 124)]
#Split the data set in three seperate dataframes based on Binary, real, ordinal
binary_data <- Filter(function(x) all(x %in% c(0, 1, NA)), data)
real_data_only <- data[c('V2', 'V35', 'V36', 'V37', 'V38', 'V84', 'V86', 'V87', 'V88', 'V89' ,'V90', 'V91')]
without_ordinal <- cbind(binary_data, real_data_only)
ordinal_data <- data.frame(data[, -which(names(data) %in% names(without_ordinal))])
#Remove variables that have more than 25% missing values
binary_data<-binary_data[, which(colMeans(!is.na(binary_data)) > 0.75)]
real_data<-real_data_only[, which(colMeans(!is.na(real_data_only)) > 0.75)]
ordinal_data<-ordinal_data[, which(colMeans(!is.na(ordinal_data)) > 0.75)]
#Outlier replacement wit NA for the real values
outlierreplacement <- function(dataframe){
dataframe %>%
map_if(is.numeric, ~ replace(.x, .x %in% boxplot.stats(.x)$out, NA)) %>%
bind_cols
}
real_data <- data.frame(outlierreplacement(real_data))
#Fix NaN values: Real variables: Mean, Binary variables: Mode
getmode <- function(v) { #Function for the mode
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
#For binary and ordinal values, replace NA values with mode
for(i in 1:ncol(binary_data)){
binary_data[ , i][is.na(binary_data[ , i])] <- getmode(binary_data[ , i])
}
for(i in 1:ncol(ordinal_data)){
ordinal_data[ , i][is.na(ordinal_data[ , i])] <- getmode(ordinal_data[ , i])
}
#For real values, the mean
for (i in 1:ncol(real_data)){
real_data[ , i][is.na(real_data[ , i])] <- mean(real_data[ , i], na.rm = TRUE)
}
#Normalization/standardization of real and ordinal values
real_ordinal_data <- cbind(real_data, ordinal_data)
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
real_ordinal_data <- as.data.frame(lapply(real_ordinal_data, min_max_norm))
#Remove variables with Chi-Squared test (Binary variables)
#Code for chi-squared correlations between dependent variable and the independent variables
#H0: The two variables are independent.
#H1: The two variables relate to each other.
x <- 1:length(binary_data)
result <- vector('list', length(x))
for(i in x){
test <- chisq.test(binary_data[,colnames(binary_data[i])], y$V122)
result[[i]] <- data.frame("X" = colnames(binary_data[i]),
"Y" = colnames(y),
"Chi.Square" = round(test$statistic,3),
"df"= test$parameter,
"p.value" = round(test$p.value, 3))
}
#print(result) # to see the p values
#p values < 0.05: reject Null hypothesis : the selected variables are dependent, so can be used to predict the dependent variable
#Feature selection: Selection variables that can be removed
x <- 1:length(binary_data)
Remove_vars <- c(rep(0,length(binary_data)))
for(i in x){
if(result[[i]][[5]]> 0.05){
Remove_vars[i] <- result[[i]][[1]]
}
}
#Remove binary variables that have p-value > 0.05
data_final_binary <- binary_data[ , !(names(binary_data) %in% Remove_vars)]
#Removal of redundant variables real and ordinal data
#Get correlation matrix. Don't forget to ignore categorical variables in this process
cormat<-round(cor(real_ordinal_data),2)
################### AUXILIARY FUNCTIONS ##########################
# Get upper triangle of the correlation matrix
get_upper_tri <- function(cormat){
cormat[lower.tri(cormat)]<- NA
return(cormat)
}
##################################################################
upper_tri <- get_upper_tri(cormat)
#Remove one variable of pair with high correlation.
related_index = c()
for (line in 1:dim(upper_tri)[1]){
for (col in 1:line){
i = col+dim(upper_tri)[1]*(line-1)
if (abs(upper_tri[i])>0.8 & abs(upper_tri[i])<1){
related_index<-c(related_index, line)
}
}
}
if (is.null(related_index)){
data_final_real <- real_ordinal_data
}else{
data_final_real<-real_ordinal_data[-related_index]
}
#Merge, y variable is V122
final_data <- cbind(data_final_binary,data_final_real)
#
saveRDS(final_data, file = "datasets/preprocessed.RDS")
library(dplyr)
library(tidyr)
library(purrr)
library(ggplot2)
#Steps in order to fix the dataset
#Load Dataset
# data<-read.csv("datasets/MI.data")
data <- read.table('datasets/MI.data', sep = ',')
data[]<-lapply(data, function(x) as.numeric(as.character(x))) #Force all datatypes to be numeric
y <- data[c(122)]#Output
#Remove variables that are useless
data <- data[-c(1, 95, 102, 105, 112:121, 123, 124)]
na_count <-sapply(data, function(y) sum(length(which(is.na(y)))))
hist(na_count, breaks = 10)
#Split the data set in three seperate dataframes based on Binary, real, ordinal
binary_data <- Filter(function(x) all(x %in% c(0, 1, NA)), data)
real_data_only <- data[c('V2', 'V35', 'V36', 'V37', 'V38', 'V84', 'V86', 'V87', 'V88', 'V89' ,'V90', 'V91')]
without_ordinal <- cbind(binary_data, real_data_only)
ordinal_data <- data.frame(data[, -which(names(data) %in% names(without_ordinal))])
#Remove variables that have more than 25% missing values
binary_data<-binary_data[, which(colMeans(!is.na(binary_data)) > 0.75)]
real_data<-real_data_only[, which(colMeans(!is.na(real_data_only)) > 0.75)]
ordinal_data<-ordinal_data[, which(colMeans(!is.na(ordinal_data)) > 0.75)]
#Outlier replacement wit NA for the real values
outlierreplacement <- function(dataframe){
dataframe %>%
map_if(is.numeric, ~ replace(.x, .x %in% boxplot.stats(.x)$out, NA)) %>%
bind_cols
}
real_data <- data.frame(outlierreplacement(real_data))
#Fix NaN values: Real variables: Mean, Binary variables: Mode
getmode <- function(v) { #Function for the mode
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
#For binary and ordinal values, replace NA values with mode
for(i in 1:ncol(binary_data)){
binary_data[ , i][is.na(binary_data[ , i])] <- getmode(binary_data[ , i])
}
for(i in 1:ncol(ordinal_data)){
ordinal_data[ , i][is.na(ordinal_data[ , i])] <- getmode(ordinal_data[ , i])
}
#For real values, the mean
for (i in 1:ncol(real_data)){
real_data[ , i][is.na(real_data[ , i])] <- mean(real_data[ , i], na.rm = TRUE)
}
# Open pdf file
pdf(file= "Histograms.pdf" )
# create a 3X3 grid
par( mfrow= c(3,3) )
# dim(real_data)
for (i in colnames(real_data)){
real_data %>% pull(i) %>% hist(main = i)
}
pdf(file= "BarCharts_ordinal.pdf" )
# create a 2X2 grid
par( mfrow= c(5,4) )
for (i in colnames(ordinal_data)){
barplot(table(ordinal_data[i]), main = i)
}
#Normalization/standardization of real and ordinal values
real_ordinal_data <- cbind(real_data, ordinal_data)
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
real_ordinal_data <- as.data.frame(lapply(real_ordinal_data, min_max_norm))
#H0: The two variables are independent.
#H1: The two variables relate to each other.
x <- 1:length(binary_data)
result <- vector('list', length(x))
for(i in x){
test <- chisq.test(binary_data[,colnames(binary_data[i])], y$V122)
result[[i]] <- data.frame("X" = colnames(binary_data[i]),
"Y" = colnames(y),
"Chi.Square" = round(test$statistic,3),
"df"= test$parameter,
"p.value" = round(test$p.value, 3))
}
#Feature selection: Selection variables that can be removed
x <- 1:length(binary_data)
Remove_vars <- c(rep(0,length(binary_data)))
for(i in x){
if(result[[i]][[5]]> 0.05){
Remove_vars[i] <- result[[i]][[1]]
}
}
#Remove binary variables that have p-value > 0.05
data_final_binary <- binary_data[ , !(names(binary_data) %in% Remove_vars)]
pdf(file= "BarCharts_binary.pdf" )
# create a 2X2 grid
par( mfrow= c(5,2) )
for (i in colnames(data_final_binary)){
barplot(table(data_final_binary[i]), main = i)
}
#Removal of redundant variables real and ordinal data
#Get correlation matrix. Don't forget to ignore categorical variables in this process
cormat<-round(cor(real_ordinal_data),2)
################### AUXILIARY FUNCTIONS ##########################
# Get upper triangle of the correlation matrix
get_upper_tri <- function(cormat){
cormat[lower.tri(cormat)]<- NA
return(cormat)
}
##################################################################
upper_tri <- get_upper_tri(cormat)
#Remove one variable of pair with high correlation.
related_index = c()
for (line in 1:dim(upper_tri)[1]){
for (col in 1:line){
i = col+dim(upper_tri)[1]*(line-1)
if (abs(upper_tri[i])>0.8 & abs(upper_tri[i])<1){
related_index<-c(related_index, line)
}
}
}
if (is.null(related_index)){
data_final_real <- real_ordinal_data
}else{
data_final_real<-real_ordinal_data[-related_index]
}
final_data <- cbind(data_final_binary,data_final_real)
#
saveRDS(final_data, file = "datasets/preprocessed.RDS")
